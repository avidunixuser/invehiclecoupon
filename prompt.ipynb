{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will a Customer Accept the Coupon?\n",
    "\n",
    "**Overview**\n",
    "\n",
    "The goal of this project is to use what you know about visualizations and probability distributions to distinguish between customers who accepted a driving coupon versus those that did not.\n",
    "\n",
    "**Data**\n",
    "\n",
    "\n",
    "This data comes to us from the UCI Machine Learning repository and was collected via a survey on Amazon Mechanical Turk. The survey describes different driving scenarios including the destination, current time, weather, passenger, etc., and then ask the person whether he will accept the coupon if he is the driver. Answers that the user will drive there ‘right away’ or ‘later before the coupon expires’ are labeled as ‘Y = 1’ and answers ‘no, I do not want the coupon’ are labeled as ‘Y = 0’.  There are five different types of coupons -- less expensive restaurants (under \\\\$20), coffee houses, carry out & take away, bar, and more expensive restaurants (\\\\$20 - \\\\$50). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverables**\n",
    "\n",
    "Your final product should be a brief report that highlights the differences between customers who did and did not accept the coupons.  To explore the data you will utilize your knowledge of plotting, statistical summaries, and visualization using Python. You will publish your findings in a public facing github repository as your first portfolio piece. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The attributes of this data set include:\n",
    "1. User attributes\n",
    "    -  Gender: male, female\n",
    "    -  Age: below 21, 21 to 25, 26 to 30, etc.\n",
    "    -  Marital Status: single, married partner, unmarried partner, or widowed\n",
    "    -  Number of children: 0, 1, or more than 1\n",
    "    -  Education: high school, bachelors degree, associates degree, or graduate degree\n",
    "    -  Occupation: architecture & engineering, business & financial, etc.\n",
    "    -  Annual income: less than \\\\$12500, \\\\$12500 - \\\\$24999, \\\\$25000 - \\\\$37499, etc.\n",
    "    -  Number of times that he/she goes to a bar: 0, less than 1, 1 to 3, 4 to 8 or greater than 8\n",
    "    -  Number of times that he/she buys takeaway food: 0, less than 1, 1 to 3, 4 to 8 or greater\n",
    "    than 8\n",
    "    -  Number of times that he/she goes to a coffee house: 0, less than 1, 1 to 3, 4 to 8 or\n",
    "    greater than 8\n",
    "    -  Number of times that he/she eats at a restaurant with average expense less than \\\\$20 per\n",
    "    person: 0, less than 1, 1 to 3, 4 to 8 or greater than 8\n",
    "    -  Number of times that he/she goes to a bar: 0, less than 1, 1 to 3, 4 to 8 or greater than 8\n",
    "\n",
    "2. Contextual attributes\n",
    "    - Driving destination: home, work, or no urgent destination\n",
    "    - Location of user, coupon and destination: we provide a map to show the geographical\n",
    "    location of the user, destination, and the venue, and we mark the distance between each\n",
    "    two places with time of driving. The user can see whether the venue is in the same\n",
    "    direction as the destination.\n",
    "    - Weather: sunny, rainy, or snowy\n",
    "    - Temperature: 30F, 55F, or 80F\n",
    "    - Time: 10AM, 2PM, or 6PM\n",
    "    - Passenger: alone, partner, kid(s), or friend(s)\n",
    "\n",
    "3. Coupon attributes\n",
    "    - time before it expires: 2 hours or one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "\n",
    "Use the prompts below to get started with your data analysis.  \n",
    "\n",
    "<h4>1. Read in the `coupons.csv` file.</h4>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/coupons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dimensions of Dataset (number of rows and columns)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Quick assessment of missing values</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.car.unique())\n",
    "(100.00 * data.isnull().sum()) / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage > 50% indicates that the particular column is not useful in terms of predictions. I just happen to use one more method below to dtermine the same. Use either method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. Investigate the dataset for missing or problematic data.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same result as above ... just different method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = data.isnull().sum()/len(data)\n",
    "null_values = null[null>0].sort_values(ascending=False)\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to remove feature whose missing value number is > 50% in this case the column \"car\" qualifies for removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('car', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Find out more missing data</h4>\n",
    "\n",
    "<h4>These columns describes how many times per month the individual being offered the coupon:</h4>\n",
    "\n",
    " - CoffeeHouse: Goes to a Coffee House\n",
    " - CarryAway: Gets Carry-Out food\n",
    " - Bar: Goes to a Bar\n",
    " - Restaurant20To50: Goes to a restaurant where the price per person is $20 to $50\n",
    " - RestaurantLessThan20: Goes to a restaurant where the price per person is less than $20\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = data.isnull().sum()/len(data)\n",
    "null_values = null[null>0].sort_values(ascending=False)\n",
    "\n",
    "i, j = 0, 0\n",
    "plots_per_row = 3\n",
    "fig, axs = plt.subplots(2,3, figsize=(20, 12))\n",
    "order = ['never', 'less1', '1~3', '4~8', 'gt8']\n",
    "\n",
    "for item in list(null_values.index):\n",
    "    sns.countplot(x=item, data=data, ax=axs[i][j], order=order, palette = 'Set3', linewidth=2,\n",
    "                   edgecolor=sns.color_palette(\"dark\", 1))\n",
    "    axs[i][j].set_xlabel(item)\n",
    "    j += 1\n",
    "    if j % plots_per_row == 0:\n",
    "        i += 1\n",
    "        j = 0\n",
    "axs[1][2].set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the coupons we are giving away are for Coffee Shops, Restaurants, and Bars; the amount of times per months people go to these places probably has a very high predictive value on whether or not they will accept the coupon. In order not to taint our data at all, it doesn't make a lot of sense to just try to impute or assign values.\n",
    "\n",
    "Let's see how many rows total we would have to drop in order to just get rid of all missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows to drop: {}'.format(len(data)- len(data.dropna())))\n",
    "print('Percent of rows to drop: {}'.format(round((len(data)- len(data.dropna()))/len(data),2)))\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 5% of our dataset. This will not terribly affect out predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. Decide what to do about your missing data -- drop, replace, other...</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing the missing values is also a valid method in this case by using Most Frequent values\n",
    "\n",
    "Other missing values in\n",
    "   - 'Bar'\n",
    "   - 'CoffeeHouse'\n",
    "   - 'CarryAway' \n",
    "   - 'RestaurantLessThan20'\n",
    "   - 'Restaurant20To50' \n",
    "      are not significant numbers. \n",
    "      \n",
    "Thus they can be replaced by the attribute with the largest count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns[data.isna().any()]:\n",
    "    largest_count = data[col].value_counts().idxmax()\n",
    "    data = data.fillna({col: largest_count})\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Let's review the data now</h3>\n",
    "\n",
    "This is demonstrate the distribution of the target variable \"Y\" \n",
    "which will tell us the acceptace vs rejection rate of the coupon by all the drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "colors = sns.color_palette('pastel')[0:5]\n",
    "sns.countplot(x='Y', data=data, ax=axs[0])\n",
    "axs[0].set_xticklabels(['No', 'Yes'], rotation = 45)\n",
    "axs[0].set_xlabel('')\n",
    "axs[1].pie(data.groupby('Y').size(), labels=['No', 'Yes'], colors = colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "axs[1].set_title('Accepted vs. Rejected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have the confirmations of these findings in our subsequent data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes('object').columns:\n",
    "    print(col, data[col].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always good to get the possible column values to explore the data further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4. What proportion of the total observations chose to accept the coupon?</h4> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_affirmative = data.loc[data['Y'] == 1].count()\n",
    "total_negative = data.loc[data['Y'] == 0].count()\n",
    "overall_total = total_affirmative + total_negative\n",
    "overall_total = data.shape[0]\n",
    "proportion_affirmative = (total_affirmative *100) / overall_total\n",
    "proportion_negative = (total_negative *100) / overall_total\n",
    "print(\"Total Observations ==> \", overall_total, \n",
    "      \"\\nTotal Affirmative ==> \" ,total_affirmative[0], \n",
    "      \"\\nTotal Negative ==> \" , total_negative[0],\n",
    "      \"\\nPropotion Affirmative ==> \"  , proportion_affirmative[0],\n",
    "      \"\\nPropotion Negative ==> \"  , proportion_negative[0])\n",
    "\n",
    "#proportion_affirmative = (100.00 * data.loc[data['Y'] == 1].count() / data.shape[0])\n",
    "#proportion_negative = (100.00 * data.loc[data['Y'] == 0].count() / data.shape[0])\n",
    "#print(proportion_affirmative)\n",
    "#print(proportion_negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the pie chart and the above assessment is very much in line with eather other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>5. Use a bar plot to visualize the `coupon` column.</h4>\n",
    "\n",
    " - Just introduced expiration as hue to see the coupon expiration pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "sns.displot(data, x='coupon', hue = 'expiration', kind = \"hist\", color = '#DC143C')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>6. Use a histogram to visualize the temperature column.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data, x= \"temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigating the Bar Coupons**\n",
    "\n",
    "Now, we will lead you through an exploration of just the bar related coupons.  \n",
    "\n",
    "1. Create a new `DataFrame` that contains just the bar coupons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bar = data.query('coupon == \"Bar\"')\n",
    "data_bar_count = data.query('coupon == \"Bar\"').count()\n",
    "data_bar_count[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What proportion of bar coupons were accepted?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_proportion = (100.00 * data_bar[data_bar['Y'] == 1].count() / data_bar.shape[0])\n",
    "print(bar_proportion[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compare the acceptance rate between those who went to a bar 3 or fewer times a month to those who went more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_affirmative =  data_bar[data_bar['Y'] == 1]\n",
    "list_of_less_than_fewer = ['never','less1', '1~3']\n",
    "total_list = ['never','less1', '1~3', 'gt8','4~8']\n",
    "three_or_fewer_bar = bar_affirmative.loc[bar_affirmative['Bar'].isin(list_of_less_than_fewer)].count()\n",
    "total_bar = data_bar.loc[data_bar['Bar'].isin(total_list)].count()\n",
    "acceptance_rate = (100.00 * three_or_fewer_bar) / total_bar\n",
    "\n",
    "print(\"\\nThree or fewer acceptance count ==> \", three_or_fewer_bar[0],\n",
    "      \"\\nTotal bar acceptance ==>\", total_bar[0],\n",
    "      \"\\nAcceptance Rate ==>\", acceptance_rate[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compare the acceptance rate between drivers who go to a bar more than once a month and are over the age of 25 to the all others.  Is there a difference?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More than once a month\n",
    "driver_frequency = ['1~3', 'gt8','4~8']\n",
    "list_above_25 = ['46','26','31','41','50plus','36']\n",
    "bar_more_than_once_a_month = bar_affirmative.loc[bar_affirmative['Bar'].isin(driver_frequency)]\n",
    "total_driver_above_25 = bar_more_than_once_a_month.loc[bar_more_than_once_a_month['age'].isin(list_above_25)].count()\n",
    "total_bar_drivers = data_bar.count()\n",
    "acceptance_rate_above_25 = (100.00 * total_driver_above_25[0]) / total_bar_drivers[0]\n",
    "\n",
    "print(\"\\nTotal driver above the age of 25 who go to the bar more than once a month ==> \", total_driver_above_25[0],\n",
    "      \"\\nTotal drivers who go to the bar ==>\", total_bar_drivers[0],\n",
    "      \"\\nAcceptance Rate of drivers > 25 ==>\", acceptance_rate_above_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_below_25 = ['21','below21']\n",
    "total_driver_below_25 = bar_more_than_once_a_month.loc[bar_more_than_once_a_month['age'].isin(list_below_25)].count()\n",
    "total_bar_drivers = data_bar.count()\n",
    "acceptance_rate_below_25 = (100.00 * total_driver_below_25[0]) / total_bar_drivers[0]\n",
    "\n",
    "print(\"\\nTotal driver above the age of 25 who go to the bar more than once a month ==> \", total_driver_below_25[0],\n",
    "      \"\\nTotal drivers who go to the bar ==>\", total_bar_drivers[0],\n",
    "      \"\\nAcceptance Rate of drivers < 25 ==>\", acceptance_rate_below_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Construct a null and alternative hypothesis for the difference between groups of drivers who go to a bar more than once a month and are over the age of 25 to all other drivers.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hypothesis</h3>\n",
    "\n",
    "<h4>The hypothesis we test is if the above difference of proportions will be zero or not equal to zero(a two tailed test will be required).</h4>\n",
    "    \n",
    "<h4>Mathematically, we represent it as:</h4>\n",
    "\n",
    " - H0 = pm - pf (=0 Null Hypothesis)\n",
    " - Ha = pm - pf (!=0 Alternate Hypothesis)\n",
    "\n",
    "<h3>Hypothesis(Null Vs Alternative)</h3>\n",
    "\n",
    "</h3>Parameter of Interest</h3>\n",
    "\n",
    " - We read the data and select only two of the relevant columns from the data set. \n",
    " - The column ‘Y’(1 if the individual \"accepted\" the coupon, else 0 if they \"Rejected\" it) \n",
    " - The variable ‘age’(Driver above the age of 25). \n",
    " - We set the parameter of interest as the difference in proportions of the individuals who Accepted the coupon\n",
    " - based on their \"age\". \n",
    " \n",
    " Formulation of the parameter of interest is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = bar_more_than_once_a_month\n",
    "new_data = data.dropna() #Drop the nan values\n",
    "\n",
    "contingency_table = pd.crosstab(new_data.Y,new_data.age.isin(list_above_25), margins = False) #Contingency Table\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table is called as a contingency table and gives us a cross-tab view of the counts pertaining to each category. Let us convert the above numbers into proportions, to get an idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = (round(pd.crosstab(new_data.Y,new_data.age).apply(lambda r:r/r.sum(),axis=0)*100,2))\n",
    "contingency_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot( x=\"Y\",data = new_data, hue='age')\n",
    "plt.title(\"Accepted/Rejected per Age group\")\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0)\n",
    "plt.xlabel(\"Accepted/Rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "data1 = contingency_table.iloc[0]\n",
    "data2 = contingency_table.iloc[1]\n",
    "print(data1,data2)\n",
    "\n",
    "stat, p = spearmanr(data1, data2)\n",
    "print('\\nstat=%.3f, p=%.3f' % (stat, p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Using alpha at 0.05 test your hypothesis and state your conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p > 0.05:\n",
    "    print('Probably independent')\n",
    "else:\n",
    "    print('Probably dependent')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use the same process to compare the acceptance rate between drivers who go to bars more than once a month and had passengers that were not a kid and had occupations other than farming, fishing, or forestry. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_passangers = ['Kid(s)']          \n",
    "list_occupation = ['Farming Fishing & Forestry']\n",
    "\n",
    "\n",
    "new_data = new_data[~new_data.passanger.isin(list_passangers)]\n",
    "new_data = new_data[~new_data.occupation.isin(list_occupation)]\n",
    "new_data.transpose()\n",
    "\n",
    "contingency_table2 = (round(pd.crosstab(new_data.Y,new_data.age).apply(lambda r:r/r.sum(),axis=0)*100,2))\n",
    "contingency_table2\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "data3 = contingency_table2.iloc[0]\n",
    "data4 = contingency_table2.iloc[1]\n",
    "print(data3,data4)\n",
    "\n",
    "stat, p = spearmanr(data3, data4)\n",
    "print('\\nstat=%.3f, p=%.3f' % (stat, p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Compare the acceptance rates between those passengers who:\n",
    "\n",
    "- go to bars more than once a month, had passengers that were not a kid, and were not widowed *OR*\n",
    "- go to bars more than once a month and are under the age of 30 *OR*\n",
    "- go to cheap restaurants more than 4 times a month and income is less than 50K. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_passangers = ['Kid(s)'] \n",
    "list_maritalstatus = ['Widowed']\n",
    "list_age = ['46', '31', '41', '50plus', '36']\n",
    "list_income =['$62500 - $74999', '$75000 - $87499', '$50000 - $62499', '$100000 or More', '$87500 - $99999']\n",
    "list_bar_gr8_4time = ['never','less1','1~3']\n",
    "\n",
    "new_data = new_data[~new_data.passanger.isin(list_passangers)]\n",
    "new_data = new_data[~new_data.maritalStatus.isin(list_maritalstatus)]\n",
    "new_data = new_data[~new_data.income.isin(list_income)]\n",
    "new_data = new_data[~new_data.Bar.isin(list_bar_gr8_4time)]\n",
    "\n",
    "contingency_table3 = (round(pd.crosstab(new_data.Y,new_data.age).apply(lambda r:r/r.sum(),axis=0)*100,2))\n",
    "contingency_table3\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "data3 = contingency_table3.iloc[0]\n",
    "data4 = contingency_table3.iloc[1]\n",
    "print(data3,data4)\n",
    "\n",
    "stat, p = spearmanr(data3, data4)\n",
    "print('\\nstat=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.  Based on these observations, what do you hypothesize about passengers who accepted the bar coupons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please see the end of independent analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Investigation\n",
    "\n",
    "Using the bar coupon example as motivation, you are to explore one of the other coupon groups and try to determine the characteristics of passengers who accept the coupons.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_coupons = data['coupon'].unique().tolist()\n",
    "list_of_coupons\n",
    "data.duplicated().sum()\n",
    "print(f\"Data Frame Dimension Before Duplicate Removal: {data.shape}\")\n",
    "data = data.drop_duplicates()\n",
    "print(f\"Data Frame Dimension After Duplicate Removal: {data.shape}\")\n",
    "data_numerical = data.select_dtypes(include=[\"int\",\"float\"])\n",
    "print(f\"Data Frame Numerical: {data_numerical.shape}\")\n",
    "data_numerical.isnull().sum()\n",
    "data_numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data Frame Dimension Before Duplicate Removal: {data.shape}\")\n",
    "data = data.drop_duplicates()\n",
    "print(f\"Data Frame Dimension After Duplicate Removal: {data.shape}\")\n",
    "data_numerical = data.select_dtypes(include=[\"int\",\"float\"])\n",
    "print(f\"Data Frame Numerical: {data_numerical.shape}\")\n",
    "data_numerical.isnull().sum()\n",
    "data_numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categorical = data.select_dtypes(exclude=[\"int\",\"float\"])\n",
    "data_categorical.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_= data_numerical.corr()\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(corr_, annot=True, fmt = \".2f\", cmap = \"YlGnBu\", linewidths=.5)\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want our data to be catogerial in order to be able to convert it to numerical values (encode it)\n",
    "\n",
    "#making a copy of the DataFrame \n",
    "data_to_convert = data.copy()\n",
    "\n",
    "data_to_convert.dtypes\n",
    "\n",
    "for col in data_to_convert.columns:\n",
    "    if data_to_convert[col].dtype == np.object: \n",
    "        data_to_convert[col]=data_to_convert[col].astype('category')\n",
    "    \n",
    "data_to_convert.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This map is to represent the frequency of visits to restaurants, bars, and coffeehouses.\n",
    "frequency_map = {\n",
    "    'never': 0,\n",
    "    'less1': 1,\n",
    "    '1~3': 2,\n",
    "    '4~8': 3,\n",
    "    'gt8': 4\n",
    "}\n",
    "\n",
    "#since some of the cols have the same categories, we can put them in a list\n",
    "frequency_cols = ['Restaurant20To50', 'RestaurantLessThan20', \n",
    "                  'CarryAway', 'CoffeeHouse', 'Bar']\n",
    "\n",
    "#use for loop to match cols with frequency_map\n",
    "for col in frequency_cols:\n",
    "    data_to_convert[col] = data_to_convert[col].map(frequency_map)\n",
    "\n",
    "\n",
    "#This map is to represent the driver's age\n",
    "age_map = {\n",
    "    'below21': 0,\n",
    "    '21': 1,\n",
    "    '26': 2,\n",
    "    '31': 3,\n",
    "    '36': 4,\n",
    "    '41': 5,\n",
    "    '46': 6,\n",
    "    '50plus': 7\n",
    "}\n",
    "\n",
    "#Here we match the age col with age map\n",
    "data_to_convert['age'] = data_to_convert['age'].map(age_map)\n",
    "\n",
    "#This map is to represent the driver's income\n",
    "income_map = {\n",
    "    'Less than $12500': 0,\n",
    "    '$12500 - $24999': 1,\n",
    "    '$25000 - $37499': 2,\n",
    "    '$37500 - $49999': 3,\n",
    "    '$50000 - $62499': 4,\n",
    "    '$62500 - $74999': 5,\n",
    "    '$75000 - $87499': 6,\n",
    "    '$87500 - $99999': 7,\n",
    "    '$100000 or More': 8\n",
    "}\n",
    "\n",
    "#Here we match the income col with income map\n",
    "data_to_convert['income'] = data_to_convert['income'].map(income_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check the categories conversion\n",
    "\n",
    "for n in data_to_convert.select_dtypes('category').columns:\n",
    "    print(n, data_to_convert[n].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "converter = LabelEncoder()\n",
    "data_to_convert['destination'] = converter.fit_transform(data_to_convert['destination'])\n",
    "data_to_convert['passanger'] = converter.fit_transform(data_to_convert['passanger'])\n",
    "data_to_convert['weather'] = converter.fit_transform(data_to_convert['weather'])\n",
    "data_to_convert['time'] = converter.fit_transform(data_to_convert['time'])\n",
    "data_to_convert['coupon'] = converter.fit_transform(data_to_convert['coupon'])\n",
    "data_to_convert['expiration'] = converter.fit_transform(data_to_convert['expiration'])\n",
    "data_to_convert['gender'] = converter.fit_transform(data_to_convert['gender'])\n",
    "data_to_convert['maritalStatus'] = converter.fit_transform(data_to_convert['maritalStatus'])\n",
    "data_to_convert['education'] = converter.fit_transform(data_to_convert['education'])\n",
    "data_to_convert['occupation'] = converter.fit_transform(data_to_convert['occupation'])\n",
    "\n",
    "#To check the categories conversion\n",
    "\n",
    "for n in data_to_convert.select_dtypes('int64').columns:\n",
    "    print(n, data_to_convert[n].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check the new data types in dataframe\n",
    "data_to_convert.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert category cols to int\n",
    "\n",
    "cols = ['age', 'income', 'Bar', 'CoffeeHouse','CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']\n",
    "for col in cols:\n",
    "  data_to_convert[col] = data_to_convert[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check that datatype converted correctly\n",
    "data_to_convert.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we check all the features in the dataset\n",
    "for n in data_to_convert.columns:\n",
    "    print(n, data_to_convert[n].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by checking for class imbalance\n",
    "\n",
    "#Making a copy of df_to_convert\n",
    "df = data_to_convert.copy()\n",
    "\n",
    "#to exclude Y col\n",
    "data_visual = df.loc[:, df.columns!='Y']\n",
    "\n",
    "#displaying distribution of all feature variables\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 18)\n",
    "data_visual.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Observations:</h4>\n",
    "\n",
    "<h4>1) The number of the number of observations for each class label is balanced.All features various accross the population.</h4>\n",
    "    \n",
    "<h4>2)From the distrabution of the values in direction_same and direction_opp wecan see that they carry the same info. Thus, we can drop the direction_oppcol </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping direction_opp col\n",
    "df.drop(columns=['direction_opp'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closer look at Y distribution\n",
    "#Checking target frequency\n",
    "sns.displot(df, x='Y')\n",
    "plt.title(\"Possibility of accepting the coupon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to confirm Y is well balanced\n",
    "df.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(20, 15))\n",
    "axes = axes.flatten()\n",
    "  \n",
    "for ax, col in zip(axes, df.select_dtypes('int64').columns):\n",
    "    sns.countplot(x=col, hue='Y', data=df, \n",
    "                  ax=ax, palette=\"Set1\");\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "destination to Y relation: The possibility of accepting the coupon is higher when the drivers have no urgent place to go.\n",
    "\n",
    "passenger to Y relation: The possibility of accepting the coupon is higher when the driver is alone.\n",
    "\n",
    "weather to Y relation: The possibility of accepting the coupon is higher when it is sunny.\n",
    "\n",
    "temperature to Y relation: The possibility of accepting the coupon is higher when when it is 80 degrees.\n",
    "\n",
    "time to Y relation: The probability of accepting the coupon is higher, if the time is 6pm or 7pm, and not during the day.\n",
    "\n",
    "coupon to Y relation: 1) The possibility of accepting coupons for resturants that cost less than 20 dollars, carry out and take away is high. 2) The acceptance and rejection of coffee house coupons is equal. 3) coupons for bars and resturants that cost between 20-50 dollars have a higher rejection rate.\n",
    "\n",
    "expiration to Y relation: Coupon that expire in one day have higher acceptance rate than the ones expiring in two hours.\n",
    "\n",
    "gender to Y relation: Both genders have the same rates.\n",
    "\n",
    "age to Y relation: drivers between 21 to 36 years old accept more coupons.\n",
    "\n",
    "maritalStatus to Y relation: Single drivers accept the coupons more.\n",
    "\n",
    "has_children to Y relation: Driver's who do not have children are more likely to accept coupons.\n",
    "\n",
    "education to Y relation: Some college, Bachelor or high school graduate are more likely to accept the coupon.\n",
    "\n",
    "occupation to Y relation: drivers who are unemployed, students, work in sales, or computers have the highest tendency to accept the copouns.\n",
    "\n",
    "income to Y relation: middle class drivers have a higher tendency to accept the copouns.\n",
    "\n",
    "Bar to Y relation: The lower the frequancy of visits the higher possiblity of accepting the copoun.\n",
    "\n",
    "CoffeeHouse to Y relation: moderate frequancy of visits has a higher possiblity of accepting the coupon.\n",
    "\n",
    "CarryAway to Y relation: moderate frequancy of visits has a higher possiblity of accepting the coupon.\n",
    "\n",
    "RestaurantLessThan20 to Y relation: moderate frequancy of visits has a higher possiblity of accepting the coupon.\n",
    "Restaurant20To50 to Y relation: if the driver went less than once they have a higher tendancy of accepting the copoun.\n",
    "toCoupon_GEQ15min to Y relation: not much difference\n",
    "toCoupon_GEQ25min to Y relation: if the distance is less than 25mins to the ccpou location it will be more likley to be accepted.\n",
    "direction_same to Y relation: if the direction is not the same, the coupons get purchased more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
